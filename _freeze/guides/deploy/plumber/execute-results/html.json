{
  "hash": "fb96bb61a03dbe34caacf944dc874508",
  "result": {
    "markdown": "---\ntitle: \"Plumber API\"\ntype: docs\nmenu:\n  main:\n    name: \"Plumber\"\n    identifier: \"deploy-plumber\"\n    parent: \"deploy-top\"\n    weight: 10\neditor_options: \n  chunk_output_type: console\naliases:\n  - ../../deploy/plumber/index.html\n---\n\n\nIn this tutorial you will learn how to deploy a TensorFlow model using a [plumber API](https://www.rplumber.io/).\n\nIn this example we will build an endpoint that takes `POST` requests sending images containing handwritten digits and returning the predicted number.\n\n## Building the model\n\nThe first thing we are going to do is to build our model. W\nWe will use the Keras API to build this model.\n\nWe will use the MNIST dataset to build our model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(keras)\nlibrary(tensorflow)\nmnist <- dataset_mnist()\n\nmnist$train$x <- (mnist$train$x/255) %>% \n  array_reshape(., dim = c(dim(.), 1))\n\nmnist$test$x <- (mnist$test$x/255) %>% \n  array_reshape(., dim = c(dim(.), 1))\n```\n:::\n\n\nNow, we are going to define our Keras model, it will be a simple convolutional neural \nnetwork.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- keras_model_sequential() %>% \n  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_flatten() %>% \n  layer_dense(units = 128, activation = \"relu\") %>% \n  layer_dense(units = 10, activation = \"softmax\")\n\nmodel %>% \n  compile(\n    loss = \"sparse_categorical_crossentropy\",\n    optimizer = \"adam\",\n    metrics = \"accuracy\"\n  )\n```\n:::\n\n\nNext, we fit the model using the MNIST dataset:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel %>% \n  fit(\n    x = mnist$train$x, y = mnist$train$y,\n    batch_size = 32,\n    epochs = 5,\n    validation_sample = 0.2,\n    verbose = 2\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 1/5\n1875/1875 - 6s - loss: 0.1822 - accuracy: 0.9459 - 6s/epoch - 3ms/step\nEpoch 2/5\n1875/1875 - 5s - loss: 0.0591 - accuracy: 0.9822 - 5s/epoch - 3ms/step\nEpoch 3/5\n1875/1875 - 5s - loss: 0.0419 - accuracy: 0.9871 - 5s/epoch - 3ms/step\nEpoch 4/5\n1875/1875 - 6s - loss: 0.0324 - accuracy: 0.9902 - 6s/epoch - 3ms/step\nEpoch 5/5\n1875/1875 - 5s - loss: 0.0259 - accuracy: 0.9916 - 5s/epoch - 3ms/step\n```\n:::\n:::\n\n\nWhen we are happy with our model accuracy in the validation dataset we can `evaluate` \nthe results on the test dataset with:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel %>% evaluate(x = mnist$test$x, y = mnist$test$y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n313/313 - 0s - loss: 0.0347 - accuracy: 0.9887 - 454ms/epoch - 1ms/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n      loss   accuracy \n0.03470162 0.98869997 \n```\n:::\n:::\n\n\nOK, we have 99% accuracy on the test dataset and we want to deploy that model.\nFirst, let's save the model in the `SavedModel` format using:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsave_model_tf(model, \"cnn-mnist\")\n```\n:::\n\n\nWith the model built and saved we can now start building our plumber API file.\n\n## Plumber API\n\nA plumber API is defined by a `.R` file with a few annotations. Here's is how we can write our `api.R` file:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(keras)\n\nmodel <- load_model_tf(\"cnn-mnist/\")\n\n#* Predicts the number in an image\n#* @param enc a base64  encoded 28x28 image\n#* @post /cnn-mnist\nfunction(enc) {\n  # decode and read the jpeg image\n  img <- jpeg::readJPEG(source = base64enc::base64decode(enc))\n  \n  # reshape\n  img <- img %>% \n    array_reshape(., dim = c(1, dim(.), 1))\n  \n  # make the prediction\n  predict_classes(model, img)\n}\n```\n:::\n\n\n\nMake sure to have the your SavedModel in the same folder as `api.R` and call:\n\n\n::: {.cell}\n\n```{.r .cell-code}\np <- plumber::plumb(\"api.R\")\np$run(port = 8000)\n```\n:::\n\n\nYou can now make requests to the [http://lcoalhost:8000/cnn-minist/](http://lcoalhost:8000/cnn-minist/) endpoint. For example, let's verify we can make a POST request to the API sending the first image from the test set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimg <- mnist$test$x[1,,,]\nmnist$test$y[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 7\n```\n:::\n:::\n\n\nFirst let's encode the image:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nencoded_img <- img %>% \n  jpeg::writeJPEG() %>% \n  base64enc::base64encode()\nencoded_img\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAoHBwgHBgoICAgLCgoLDhgQDg0NDh0VFhEYIx8lJCIfIiEmKzcvJik0KSEiMEExNDk7Pj4+JS5ESUM8SDc9Pjv/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APHIYJbmZYYInllc4VEUszH2A6064tbi0k8q5glgcfwyIVP5GoqKsWGoXel3sd7YXD29zESUljOGXIwf0JrpLf4o+MLeNUbVftAU5BuIUlPTplhn/wDVXQ+PNcvk8D6bpmtPbz6vqDi9lCwqhtocYRRtHU8k9+orzKius8CeHrS/nutd1pWGiaQnm3GBnznyNsQ+p/w4zWL4h1u48Ra7d6rcDa1w+VQdEUcKo+gAFZtFbsfjDVIPB7+FoRBHYyymWVlT95JyDgknGMgdADx1rCor/9k=\"\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nreq <- httr::POST(\"http://localhost:8000/cnn-mnist\",\n           body = list(enc = encoded_img), \n           encode = \"json\")\nhttr::content(req)\n```\n:::\n\n\n```\n[[1]]\n[1] 7\n```\n\nYou can also access the Swagger interface by accessing [http://127.0.0.1:8000/__swagger__/](http://127.0.0.1:8000/__swagger__/) and paste the encoded string in the UI to visualize the result.\n\n![](images/swagger.png)\n\n## More advanced models\n\nWhen building more advanced models you may not be able to save the entire model using the `save_model_tf` function. In this case you can use the `save_model_weights_tf` function. \n\nFor example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsave_model_weights_tf(model, \" cnn-model-weights\")\n```\n:::\n\n\nThen, in the `api.R` file whenn loading the model you will need to rebuild the model using the exact same code that you used when training and saving and then use `load_model_weights_tf` to load\nthe model weights.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- keras_model_sequential() %>% \n  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_flatten() %>% \n  layer_dense(units = 128, activation = \"relu\") %>% \n  layer_dense(units = 10, activation = \"softmax\")\n\nload_model_weights_tf(model, \"cnn-model-weights\")\n```\n:::\n\n\n## Hosting the plumber API\n\nPlumber is very flexible and allows multiple hosting options. See the plumber [Hostinng documentation](https://www.rplumber.io/docs/hosting.html) for more information.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}